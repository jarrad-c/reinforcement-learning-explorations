{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "playing_with_stable_baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2",
        "colab_type": "text"
      },
      "source": [
        "## mk3 and street fighter with stable baselines\n",
        "\n",
        "## can train on all models that support multibinary actions (PPO2, A2C)\n",
        "\n",
        "Models need finetuning, they don't perfom well with the base parameters\n",
        "\n",
        "Github: [https://github.com/hill-a/stable-baselines](https://github.com/hill-a/stable-baselines)\n",
        "\n",
        "Really good documentation: [https://stable-baselines.readthedocs.io/](https://stable-baselines.readthedocs.io/)\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/hill-a/stable-baselines).\n",
        "\n",
        "```\n",
        "sudo apt-get update && sudo apt-get install cmake libopenmpi-dev zlib1g-dev\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines[mpi]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWskDE2c9WoN",
        "colab_type": "code",
        "outputId": "eff5e3b5-9396-48d8-b00c-e8076f2ea8c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "!pip install stable-baselines[mpi]==2.8.0\n",
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines[mpi]==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/75/6f92ac720de62be8c16ec652d22c9296a90d857cd636d043de16de8128ab/stable_baselines-2.8.0-py3-none-any.whl (222kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (0.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (0.25.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (1.3.3)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (0.15.4)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.8.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]==2.8.0) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (4.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]==2.8.0) (42.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (0.16.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (0.46)\n",
            "Installing collected packages: stable-baselines\n",
            "  Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgtcIH7RzsDm",
        "colab_type": "code",
        "outputId": "004aef7e-cb7c-41dd-977e-d5ff906a2de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "!pip install gym-retro atari_py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym-retro\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/2b/bee76fbe439a8a600854fb41fafcfad7efa57d1f3107bbca48ac4a1387cd/gym_retro-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (162.0MB)\n",
            "\u001b[K     |████████████████████████████████| 162.0MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: atari_py in /usr/local/lib/python3.6/dist-packages (0.2.6)\n",
            "Requirement already satisfied: pyglet==1.*,>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from gym-retro) (1.3.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-retro) (0.15.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from atari_py) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari_py) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.*,>=1.3.2->gym-retro) (0.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym->gym-retro) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-retro) (1.3.3)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-retro) (1.2.2)\n",
            "Installing collected packages: gym-retro\n",
            "Successfully installed gym-retro-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm",
        "colab_type": "text"
      },
      "source": [
        "## Import policy, RL agent, ROM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQbjEr0DPWJ8",
        "colab_type": "text"
      },
      "source": [
        "Import roms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4WKSqDAO3p_",
        "colab_type": "code",
        "outputId": "c73bd3ba-8acc-461d-e4ca-bb9182219916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWljkpDtO7b7",
        "colab_type": "code",
        "outputId": "062330cd-9ed2-45b8-c3bb-30c42bff79f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!python -m retro.import ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing 20 potential games...\n",
            "Importing MortalKombat3-Genesis\n",
            "Importing StreetFighterIISpecialChampionEdition-Genesis\n",
            "Imported 2 games\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "colab_type": "code",
        "outputId": "84acf164-322a-4ced-a194-d95c4e39c5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import gym\n",
        "import retro\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines.common.policies import MlpPolicy, CnnPolicy\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines import PPO2,A2C"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl",
        "colab_type": "text"
      },
      "source": [
        "Helper function to evaluate the agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63M8mSKR-6Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, num_steps=1000):\n",
        "  \"\"\"\n",
        "  Evaluate a RL agent\n",
        "  :param model: (BaseRLModel object) the RL Agent\n",
        "  :param num_steps: (int) number of timesteps to evaluate it\n",
        "  :return: (float) Mean reward for the last 100 episodes\n",
        "  \"\"\"\n",
        "  episode_rewards = [0.0]\n",
        "  obs = env.reset()\n",
        "  for i in range(num_steps):\n",
        "      # _states are only useful when using LSTM policies\n",
        "      action, _states = model.predict(obs)\n",
        "      # here, action, rewards and dones are arrays\n",
        "      # because we are using vectorized env\n",
        "      obs, rewards, dones, info = env.step(action)\n",
        "      \n",
        "      # Stats\n",
        "      episode_rewards[-1] += rewards[0]\n",
        "      if dones[0]:\n",
        "          obs = env.reset()\n",
        "          episode_rewards.append(0.0)\n",
        "  # Compute mean reward for the last 100 episodes\n",
        "  mean_100ep_reward = round(np.mean(episode_rewards[-100:]), 1)\n",
        "  print(\"Mean reward:\", mean_100ep_reward, \"Num episodes:\", len(episode_rewards))\n",
        "  \n",
        "  return mean_100ep_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB46V68Y5Xp4",
        "colab_type": "text"
      },
      "source": [
        "## Define a Callback Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-9N59qG4MMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_mean_reward, n_steps = -np.inf, 0\n",
        "\n",
        "def callback(_locals, _globals):\n",
        "    \"\"\"\n",
        "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
        "    :param _locals: (dict)\n",
        "    :param _globals: (dict)\n",
        "    \"\"\"\n",
        "    global n_steps, best_mean_reward\n",
        "    # Print stats every 1000 calls\n",
        "    if (n_steps + 1) % 1000 == 0:\n",
        "        # Evaluate policy training performance\n",
        "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
        "        if len(x) > 0:\n",
        "            mean_reward = np.mean(y[-100:])\n",
        "            print(x[-1], 'timesteps')\n",
        "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
        "\n",
        "            # New best model, you could save the agent here\n",
        "            if mean_reward > best_mean_reward:\n",
        "                best_mean_reward = mean_reward\n",
        "                # Example for saving best model\n",
        "                print(\"Saving new best model\")\n",
        "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
        "    n_steps += 1\n",
        "    # Returning False will stop training early\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO68ZMHzTNqO",
        "colab_type": "text"
      },
      "source": [
        "## Create log directory to store eval metrics and make env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fyx1fQ54diT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from stable_baselines.bench import Monitor\n",
        "from stable_baselines import results_plotter\n",
        "from stable_baselines.results_plotter import load_results, ts2xy\n",
        "\n",
        "log_dir = \"/tmp/gym/\"\n",
        "\n",
        "def create_env(env_id):\n",
        "  os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "  # Create and wrap the environment\n",
        "  env = retro.make(game=env_id)\n",
        "\n",
        "  # Logs will be saved in log_dir/monitor.csv\n",
        "  env = Monitor(env, log_dir, allow_early_resets=True)\n",
        "\n",
        "  # Because we use parameter noise, we should use a MlpPolicy with layer normalization\n",
        "  return DummyVecEnv([lambda: env])  # The algorithms require a vectorized environment to run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiP5WpV5apxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = create_env('MortalKombat3-Genesis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb83sKHr5ehc",
        "colab_type": "code",
        "outputId": "17fe88c5-0278-4cbc-f3e1-9679499991db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "# Choose model\n",
        "model = PPO2(MlpPolicy, env, verbose=0)\n",
        "# model = A2C(CnnPolicy, env, verbose=0)\n",
        "\n",
        "# Random Agent evaluation, before training\n",
        "mean_reward_before_train = evaluate(model, num_steps=10000)\n",
        "\n",
        "# Train the agent\n",
        "model.learn(total_timesteps=int(50000), callback=callback)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:458: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Mean reward: 146.2 Num episodes: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kziA4kgkUVTq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation and plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AmHoUwjCH-3",
        "colab_type": "code",
        "outputId": "597cd2b1-b4c1-4420-cd7c-0b714f82911a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluate agent after training\n",
        "mean_reward_after_train = evaluate(model, num_steps=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean reward: 436.5 Num episodes: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ4tbJpa5nWv",
        "colab_type": "code",
        "outputId": "884065d5-281d-4a64-b6d2-9ca85ee246f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from stable_baselines import results_plotter\n",
        "\n",
        "# Helper from the library\n",
        "results_plotter.plot_results([log_dir], 10000, results_plotter.X_TIMESTEPS, \"PPO2 Mortal Kombat\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAACICAYAAADqIJGqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5MfrjTlaInP",
        "colab_type": "text"
      },
      "source": [
        "## Save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrqrsQIZ0-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the agent\n",
        "os.mkdir('models')\n",
        "model.save(\"models/ppo2_mk3\")\n",
        "del model  # delete trained model to demonstrate loading"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW0HpFgLZ65p",
        "colab_type": "code",
        "outputId": "e163e451-5a52-4aa1-b324-b9675f3675c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "model = PPO2.load(\"models/ppo2_mk3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:458: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnrjapeCUby1",
        "colab_type": "text"
      },
      "source": [
        "## Store game play by trained model in mp4\n",
        "\n",
        "not working for trained model yet, works for random moves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhn47zY17_Lx",
        "colab_type": "code",
        "outputId": "4ebc2f13-0388-405b-a9e2-57c7fc9a8bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "source": [
        "import gym\n",
        "from stable_baselines.common.vec_env import VecVideoRecorder\n",
        "\n",
        "env_id = 'MortalKombat3-Genesis'\n",
        "video_folder = 'logs/videos/'\n",
        "video_length = 100000\n",
        "\n",
        "env = create_env('MortalKombat3-Genesis')\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "# Record the video starting at the first step\n",
        "env = VecVideoRecorder(env, video_folder,\n",
        "                       record_video_trigger=lambda x: x == 0, video_length=video_length,\n",
        "                       name_prefix=\"random-agent-{}\".format(env_id))\n",
        "\n",
        "env.reset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         ...,\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64]],\n",
              "\n",
              "        [[64, 68, 64],\n",
              "         [64, 32, 32],\n",
              "         [64, 68, 64],\n",
              "         ...,\n",
              "         [64, 68, 64],\n",
              "         [64, 32, 32],\n",
              "         [64, 68, 64]],\n",
              "\n",
              "        [[64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         ...,\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64],\n",
              "         [64, 68, 64]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[96, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         ...,\n",
              "         [96, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         [96, 32, 32]],\n",
              "\n",
              "        [[64, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         ...,\n",
              "         [96, 32, 32],\n",
              "         [96, 32, 32],\n",
              "         [64, 32, 32]],\n",
              "\n",
              "        [[96, 32, 32],\n",
              "         [64, 32, 32],\n",
              "         [64, 32, 32],\n",
              "         ...,\n",
              "         [64, 32, 32],\n",
              "         [64, 32, 32],\n",
              "         [96, 32, 32]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1hXGnBrUiZ8",
        "colab_type": "text"
      },
      "source": [
        "Store game play by the trained model in gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgGBZp2hQBJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "\n",
        "model.set_env(env)\n",
        "\n",
        "images = []\n",
        "obs = model.env.reset()\n",
        "img = model.env.render(mode='rgb_array')\n",
        "done = False\n",
        "while not done:\n",
        "    images.append(img)\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, done ,_ = model.env.step(action)\n",
        "    img = model.env.render(mode='rgb_array')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiUEp7HlXtPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageio.mimsave('mk3_ppo2.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}